{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Buiding CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "#import Keras lib and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32,(3,3),input_shape = (64,64,3),activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Full connection\n",
    "classifier.add(Dense( 128,activation='relu'))\n",
    "classifier.add(Dense( 1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN\n",
    "classifier.compile(optimizer='adam', loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Use it to generate more images based on existing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from Keras Documentation: https://keras.io/preprocessing/image/\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "                                                r'D:\\Google Drive\\Deep Learning Dataset\\Convolutional_Neural_Networks\\dataset\\training_set', #change path\n",
    "                                                target_size=(64, 64), #same as the input shape\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "                                            r'D:\\Google Drive\\Deep Learning Dataset\\Convolutional_Neural_Networks\\dataset\\test_set',\n",
    "                                            target_size=(64, 64), #same as the input shape\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 857s 107ms/step - loss: 0.3803 - acc: 0.8205 - val_loss: 0.6978 - val_acc: 0.7120\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 715s 89ms/step - loss: 0.1333 - acc: 0.9499 - val_loss: 0.9112 - val_acc: 0.7611\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 716s 89ms/step - loss: 0.0710 - acc: 0.9747 - val_loss: 1.0707 - val_acc: 0.7480\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 716s 90ms/step - loss: 0.0484 - acc: 0.9827 - val_loss: 1.2105 - val_acc: 0.7604\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 720s 90ms/step - loss: 0.0374 - acc: 0.9870 - val_loss: 1.2958 - val_acc: 0.7541\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 725s 91ms/step - loss: 0.0312 - acc: 0.9893 - val_loss: 1.2114 - val_acc: 0.7559\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 717s 90ms/step - loss: 0.0267 - acc: 0.9909 - val_loss: 1.4212 - val_acc: 0.7576\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 754s 94ms/step - loss: 0.0229 - acc: 0.9925 - val_loss: 1.4530 - val_acc: 0.7338\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 738s 92ms/step - loss: 0.0212 - acc: 0.9929 - val_loss: 1.1687 - val_acc: 0.7539\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 736s 92ms/step - loss: 0.0192 - acc: 0.9937 - val_loss: 1.3462 - val_acc: 0.7549\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 722s 90ms/step - loss: 0.0183 - acc: 0.9939 - val_loss: 1.3543 - val_acc: 0.7546\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 727s 91ms/step - loss: 0.0186 - acc: 0.9942 - val_loss: 1.3313 - val_acc: 0.7535\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 719s 90ms/step - loss: 0.0186 - acc: 0.9942 - val_loss: 1.5639 - val_acc: 0.7516\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 721s 90ms/step - loss: 0.0231 - acc: 0.9929 - val_loss: 1.5361 - val_acc: 0.7449\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 720s 90ms/step - loss: 0.0212 - acc: 0.9934 - val_loss: 1.5406 - val_acc: 0.7596\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 717s 90ms/step - loss: 0.0328 - acc: 0.9899 - val_loss: 1.2839 - val_acc: 0.7554\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 717s 90ms/step - loss: 0.0408 - acc: 0.9872 - val_loss: 1.2234 - val_acc: 0.7551\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 716s 89ms/step - loss: 0.0294 - acc: 0.9905 - val_loss: 1.4632 - val_acc: 0.7528\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 712s 89ms/step - loss: 0.0352 - acc: 0.9884 - val_loss: 1.3595 - val_acc: 0.7540\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 713s 89ms/step - loss: 0.0390 - acc: 0.9873 - val_loss: 1.2144 - val_acc: 0.7563\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 713s 89ms/step - loss: 0.0473 - acc: 0.9849 - val_loss: 1.0766 - val_acc: 0.7486\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 713s 89ms/step - loss: 0.0435 - acc: 0.9862 - val_loss: 1.2611 - val_acc: 0.7587\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 712s 89ms/step - loss: 0.0501 - acc: 0.9840 - val_loss: 1.1221 - val_acc: 0.7434\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 712s 89ms/step - loss: 0.0881 - acc: 0.9699 - val_loss: 0.9608 - val_acc: 0.7494\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 711s 89ms/step - loss: 0.0520 - acc: 0.9831 - val_loss: 1.1770 - val_acc: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25308a46630>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "                        training_set,\n",
    "                        steps_per_epoch=8000, # number of images you want to train in each epoch, I used all images\n",
    "                        epochs=25, #if you do not want it to run too many times, just reduce it\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=2000 # number of images in the test set\n",
    "                        )\n",
    "\n",
    "#Warning!!! The excution will takes a long time to run, time depends on the the hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('D:\\Google Drive\\Deep Learning Dataset\\Convolutional_Neural_Networks\\dataset\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to reduce to running time is to add callback early stop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience = 2) #it means the training will stop after two epochs without no improvement\n",
    "\n",
    "classifier.fit_generator(\n",
    "                        training_set,\n",
    "                        steps_per_epoch=8000, # number of images in the training folders\n",
    "                        epochs=25, #if you do not want it to run too many times, just reduce it\n",
    "                        validation_data=test_set,\n",
    "                        validaticallableableableteps=2000 # number of images in the test set\n",
    "                        callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways to improve the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add more convoluations (Part 1 Step 1), which means repeat step 1 and step 2\n",
    "2. ADD more layers (Part 1 Step 4)\n",
    "3. Increase the image shape/size (Part 1 Step 1, from 64 up to 256, and also Part 2 the target_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model(r'D:\\Google Drive\\Deep Learning Dataset\\Convolutional_Neural_Networks\\dataset\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r'D:\\Google Drive\\Deep Learning Dataset\\Convolutional_Neural_Networks\\dataset\\single_prediction\\cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print (prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
